# This file defines the environment for docker-compose for running a 'production' version.
# If you want to have them available also within the docker containers, you need to add them to the
# 'environments' section of x-airflow-common

ENV_NAME=production

# ports where the UIs will be served
WEBSERVER_PORT=<port>
WEBAPP_PORT=<port>

AIRFLOW_USER=<airflow_user>
#AIRFLOW_PASSWORD=<password>

MONGO_USER=<mongo_user>
#MONGO_PASSWORD=<password>
#MONGO_HOST=<kraken_url> # if this deployment must access this service on another machine
MONGO_HOST=mongodb-service # if this deployment can access this service within the same docker-compose network
MONGO_PORT=<port>

POSTGRES_HOST=<kraken_url>  # access on another machine
#POSTGRES_HOST=postgres-service  # access within docker-compose network
MONGO_PORT=<port>
POSTGRES_USER=<postgres_user>
#POSTGRES_PASSWORD=<password>
POSTGRES_DB=airflow

REDIS_HOST=<kraken_url>  # access on another machine
#REDIS_HOST=redis-service  # access within docker-compose network
REDIS_PORT=<port>

# all mounts (backup pool folders, results pool folders, instruments) need to be available in MOUNTS_PATH, cf. Readme
MOUNTS_PATH=/home/kraken-user/alphakraken/production/mounts

# location of BACKUP_POOL_FOLDER & QUANTING_POOL_FOLDER
POOL_BASE_PATH=/fs/pool

# this is the folder where backed up files will be read from by the slurm script (relative to /fs/pool/)
BACKUP_POOL_FOLDER=pool-backup    # //samba-pool-backup/
# subfolders: /test2, /test3, ...

# this is the folder where settings are read and output will be written to by the slurm script (relative to /fs/pool/)
QUANTING_POOL_FOLDER=pool-alphakraken   # //samba-pool-alphakraken/
# subfolders: /output, /settings, /airflow_log
